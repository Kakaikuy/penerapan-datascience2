# -*- coding: utf-8 -*-
"""Penerapan_Data_Science_P2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11eEIKTwRzYQNEfsatSxmMkBFwtM4kx_N

### Impor Library
"""

import pandas as pd
import numpy as np
import re
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.utils import resample
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler,OrdinalEncoder
from sklearn.decomposition import PCA
from sklearn.preprocessing import OneHotEncoder
import joblib
import os
from sklearn.utils import shuffle
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import OrdinalEncoder
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

from google.colab import drive
drive.mount('/content/drive')

"""Load Dataset"""

student_df = pd.read_csv('/content/drive/MyDrive/Dataset/datascience2/data.csv',delimiter=";")

"""### Data Understanding"""

# Menampilkan 5 data pertama
student_df.head()

student_df.info()

student_df.describe()

"""### Cek Missing Value dan Duplikasi"""

student_df.isnull().sum()

# Cek duplikasi
print("Jumlah duplikasi: ", student_df.duplicated().sum())

"""### pisah kategorikal dan numerikal"""

newstudent_df = student_df.copy()
numerical_column = [
    "Previous_qualification_grade",
    "Admission_grade",
    "Age_at_enrollment",
    "Curricular_units_1st_sem_credited",
    "Curricular_units_1st_sem_enrolled",
    "Curricular_units_1st_sem_evaluations",
    "Curricular_units_1st_sem_approved",
    "Curricular_units_1st_sem_grade",
    "Curricular_units_1st_sem_without_evaluations",
    "Curricular_units_2nd_sem_credited",
    "Curricular_units_2nd_sem_enrolled",
    "Curricular_units_2nd_sem_evaluations",
    "Curricular_units_2nd_sem_approved",
    "Curricular_units_2nd_sem_grade",
    "Curricular_units_2nd_sem_without_evaluations",
    "Unemployment_rate",
    "Inflation_rate",
    "GDP",
]

for col in numerical_column:
  newstudent_df[col] = newstudent_df[col].astype("float64")

newstudent_df.drop(["Curricular_units_1st_sem_without_evaluations", "Curricular_units_1st_sem_credited", "Curricular_units_2nd_sem_credited", "Curricular_units_2nd_sem_without_evaluations","Application_order"], axis=1, inplace=True)

numerical_column = [
    "Previous_qualification_grade",
    "Admission_grade",
    "Age_at_enrollment",
    "Curricular_units_1st_sem_enrolled",
    "Curricular_units_1st_sem_evaluations",
    "Curricular_units_1st_sem_approved",
    "Curricular_units_1st_sem_grade",
    "Curricular_units_2nd_sem_enrolled",
    "Curricular_units_2nd_sem_evaluations",
    "Curricular_units_2nd_sem_approved",
    "Curricular_units_2nd_sem_grade",
    "Unemployment_rate",
    "Inflation_rate",
    "GDP",
]
newstudent_df[numerical_column].describe()

newstudent_df.head(15)

categorical_columns = [
      "Marital_status",
      "Application_mode",
      "Course",
      "Previous_qualification",
      "Mothers_qualification",
      "Fathers_qualification",
      "Mothers_occupation",
      "Fathers_occupation",
      "Displaced",
      "Debtor",
      "Tuition_fees_up_to_date",
      "Gender",
      "Scholarship_holder",
      "Status",
]

for col in categorical_columns:
    print(newstudent_df[col].value_counts())

newstudent_df.info()

# Gabungkan semua kolom yang ingin dihapus
columns_to_drop = [
    "Nacionality", "Educational_special_needs", "International", "Daytime_evening_attendance",
    "Curricular_units_1st_sem_without_evaluations", "Curricular_units_1st_sem_credited",
    "Curricular_units_2nd_sem_credited", "Curricular_units_2nd_sem_without_evaluations",
    "Application_order"
]

# Hapus hanya kolom yang tersedia di DataFrame
available_cols = [col for col in columns_to_drop if col in newstudent_df.columns]
newstudent_df.drop(columns=available_cols, inplace=True)

newstudent_df[categorical_columns].isna().sum()

cleanstudent_df = newstudent_df.copy()

cleanstudent_df.describe(include="all")

cleanstudent_df.info()

"""### EDA"""

categorical_columns = [
      "Marital_status",
      "Application_mode",
      "Course",
      "Previous_qualification",
      "Mothers_qualification",
      "Fathers_qualification",
      "Mothers_occupation",
      "Fathers_occupation",
      "Displaced",
      "Debtor",
      "Tuition_fees_up_to_date",
      "Gender",
      "Scholarship_holder",
      "Status",
]

fig, ax = plt.subplots(len(categorical_columns), 1,figsize=(20,40))
for i, feature in enumerate(categorical_columns):
    sns.countplot(data=cleanstudent_df, y=feature, ax=ax[i])
plt.show()

# Visualisasi Kategorikal
categorical_features = [
      "Marital_status",
      "Application_mode",
      "Course",
      "Previous_qualification",
      "Mothers_qualification",
      "Fathers_qualification",
      "Mothers_occupation",
      "Fathers_occupation",
      "Displaced",
      "Debtor",
      "Tuition_fees_up_to_date",
      "Gender",
      "Scholarship_holder",
      "Status",
]

for col in categorical_features:
    plt.figure(figsize=(10, 4))
    sns.countplot(data=student_df, x=col, hue='Status', palette='Set2')
    plt.title(f'Distribusi {col} berdasarkan Status')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

numerical_features = ['Admission_grade', 'Age_at_enrollment', 'Previous_qualification_grade',
                      'Curricular_units_1st_sem_approved', 'Curricular_units_2nd_sem_approved']

for col in numerical_features:
    plt.figure(figsize=(10, 4))
    sns.boxplot(data=student_df, x='Status', y=col, palette='Set3')
    plt.title(f'Distribusi {col} berdasarkan Status')
    plt.tight_layout()
    plt.show()

def numerical_dis_plot(features, df, segment_feature=None, showfliers=True):
    fig, ax = plt.subplots(len(features), 1,figsize=(15,30))
    for i, feature in enumerate(features):
        if segment_feature:
            sns.boxplot(y=segment_feature, x=feature, data=df, ax=ax[i], showfliers=showfliers)
            ax[i].set_ylabel(None)
        else:
            sns.boxplot(x=feature, data=df, ax=ax[i], showfliers=showfliers)
    plt.tight_layout()
    plt.show()

numerical_dis_plot(
    features=numerical_column,
    df=cleanstudent_df
)

def categorical_plot(features, df, segment_feature=None):
    fig, ax = plt.subplots(len(features), 1,figsize=(10,20))
    for i, feature in enumerate(features):
        if segment_feature:
            sns.countplot(data=df, y=segment_feature, hue=feature, ax=ax[i])
        else:
            sns.countplot(data=df, x=feature, ax=ax[i])
    plt.tight_layout()
    plt.show()

categorical_plot(
    features=[
      "Marital_status",
      "Application_mode",
      "Course",
      "Previous_qualification",
      "Mothers_qualification",
      "Fathers_qualification",
      "Mothers_occupation",
      "Fathers_occupation",
      "Displaced",
      "Debtor",
      "Tuition_fees_up_to_date",
      "Gender",
      "Scholarship_holder",
      "Status",
    ],
    df=cleanstudent_df,
    segment_feature="Status"
)

numerical_features = [
    "Previous_qualification_grade",
    "Admission_grade",
    "Age_at_enrollment",
    "Curricular_units_1st_sem_enrolled",
    "Curricular_units_1st_sem_evaluations",
    "Curricular_units_1st_sem_approved",
    "Curricular_units_1st_sem_grade",
    "Curricular_units_2nd_sem_enrolled",
    "Curricular_units_2nd_sem_evaluations",
    "Curricular_units_2nd_sem_approved",
    "Curricular_units_2nd_sem_grade",
    "Unemployment_rate",
    "Inflation_rate",
    "GDP",
]

# Hitung korelasi antar fitur numerik
corr_matrix = cleanstudent_df[numerical_features].corr()

# Visualisasi heatmap korelasi
plt.figure(figsize=(14, 10))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title("Correlation Matrix of Numerical Features", fontsize=16)
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""Data Preprocessing"""

train_df, test_df = train_test_split(cleanstudent_df, test_size=0.2, random_state=42, shuffle=True)
train_df.reset_index(drop=True, inplace=True)
test_df.reset_index(drop=True, inplace=True)

sns.countplot(data=train_df, x="Status")
plt.show()

train_df.Status.value_counts()

"""### Oversampling"""

df_majority_1 = train_df[train_df.Status == "Graduate"]
df_majority_2 = train_df[train_df.Status == "Dropout"]
df_minority = train_df[train_df.Status == "Enrolled"]

df_majority_2_us = resample(df_majority_2, n_samples=1791, random_state=42)
df_minority_us = resample(df_minority, n_samples=1791, random_state=42)

balanced_train_df = pd.concat([df_majority_1, df_majority_2_us, df_minority_us], ignore_index=True)
balanced_train_df = shuffle(balanced_train_df, random_state=42).reset_index(drop=True)

sns.countplot(data=balanced_train_df, x="Status")
plt.show()

X_train = balanced_train_df.drop(columns="Status")
y_train = balanced_train_df["Status"]

X_test = test_df.drop(columns="Status")
y_test = test_df["Status"]

"""Encoding dan Scalling"""

def scaling(features, df, df_test=None):
    os.makedirs('model', exist_ok=True)
    if df_test is not None:
        df = df.copy()
        df_test = df_test.copy()
        for feature in features:
            scaler = MinMaxScaler()
            X = np.asanyarray(df[feature])
            X = X.reshape(-1,1)
            scaler.fit(X)
            df["{}".format(feature)] = scaler.transform(X)
            joblib.dump(scaler, "model/scaler_{}.joblib".format(feature))

            X_test = np.asanyarray(df_test[feature])
            X_test = X_test.reshape(-1,1)
            df_test["{}".format(feature)] = scaler.transform(X_test)
        return df, df_test
    else:
        df = df.copy()
        for feature in features:
            scaler = MinMaxScaler()
            X = np.asanyarray(df[feature])
            X = X.reshape(-1,1)
            scaler.fit(X)
            df["{}".format(feature)] = scaler.transform(X)
            joblib.dump(scaler, "model/scaler_{}.joblib".format(feature))
        return df

def encoding(features, df, df_test=None):
    os.makedirs("model", exist_ok=True)
    df = df.copy()
    if df_test is not None:
        df_test = df_test.copy()

    for feature in features:
        enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
        df[[feature]] = df[[feature]].astype(str)
        if df_test is not None:
            df_test[[feature]] = df_test[[feature]].astype(str)

        enc.fit(df[[feature]])
        df[[feature]] = enc.transform(df[[feature]])
        if df_test is not None:
            df_test[[feature]] = enc.transform(df_test[[feature]])

        joblib.dump(enc, f"model/encoder_{feature}.joblib")

    return (df, df_test) if df_test is not None else df

numerical_columns = [
    "Previous_qualification_grade",
    "Admission_grade",
    "Age_at_enrollment",
    "Curricular_units_1st_sem_enrolled",
    "Curricular_units_1st_sem_evaluations",
    "Curricular_units_1st_sem_approved",
    "Curricular_units_1st_sem_grade",
    "Curricular_units_2nd_sem_enrolled",
    "Curricular_units_2nd_sem_evaluations",
    "Curricular_units_2nd_sem_approved",
    "Curricular_units_2nd_sem_grade",
    "Unemployment_rate",
    "Inflation_rate",
    "GDP",
]

categorical_columns = [
    "Marital_status",
    "Application_mode",
    "Course",
    "Previous_qualification",
    "Mothers_qualification",
    "Fathers_qualification",
    "Mothers_occupation",
    "Fathers_occupation",
    "Displaced",
    "Debtor",
    "Tuition_fees_up_to_date",
    "Gender",
    "Scholarship_holder",
]

X_train_scaled, X_test_scaled = scaling(numerical_columns, X_train, X_test)
X_train_encoded, X_test_encoded = encoding(categorical_columns, X_train_scaled, X_test_scaled)

encoder = LabelEncoder()
encoder.fit(y_train)  # Fit dari training (balanced)
y_train_encoded = encoder.transform(y_train)
y_test_encoded = encoder.transform(y_test)
joblib.dump(encoder, "model/encoder_target.joblib")

"""SMOTE"""

smote = SMOTE(random_state=42)
X_smote, y_smote = smote.fit_resample(X_train_encoded, y_train_encoded)

"""PCA (Principal Component Analysis)"""

pca_numerical_columns_1 = ['Curricular_units_1st_sem_enrolled',
    'Curricular_units_1st_sem_evaluations',
    'Curricular_units_1st_sem_approved',
    'Curricular_units_1st_sem_grade',
    'Curricular_units_2nd_sem_enrolled',
    'Curricular_units_2nd_sem_evaluations',
    'Curricular_units_2nd_sem_approved',
    'Curricular_units_2nd_sem_grade',]
pca_numerical_columns_2 = [
    'Previous_qualification_grade',
    'Admission_grade',
    'Age_at_enrollment',
    'Unemployment_rate',
    'Inflation_rate',
    'GDP',]

train_pca_df = pd.DataFrame(X_smote, columns=X_train_encoded.columns)
test_pca_df = X_test_encoded.copy()

def apply_pca_train(df, columns, n_components, pca_name):
    os.makedirs("model", exist_ok=True)

    # Visualisasi explained variance
    pca_full = PCA(n_components=len(columns), random_state=123)
    pca_full.fit(df[columns])

    var_exp = pca_full.explained_variance_ratio_.round(3)
    cum_var_exp = np.cumsum(var_exp)

    plt.figure(figsize=(8,4))
    plt.bar(range(len(columns)), var_exp, alpha=0.5, align='center', label='Individual explained variance')
    plt.step(range(len(columns)), cum_var_exp, where='mid', label='Cumulative explained variance')
    plt.ylabel('Explained variance ratio')
    plt.xlabel('Principal component index')
    plt.title(f"PCA Explained Variance: {pca_name}")
    plt.legend(loc='best')
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # Fit PCA dengan n_components yang diinginkan
    pca = PCA(n_components=n_components, random_state=123)
    pca.fit(df[columns])
    joblib.dump(pca, f"model/pca_{pca_name}.joblib")

    # Transformasi data
    princ_comp = pca.transform(df[columns])
    pc_cols = [f"pc{pca_name}_{i+1}" for i in range(n_components)]
    df[pc_cols] = pd.DataFrame(princ_comp, index=df.index, columns=pc_cols)

    # Drop kolom asli
    df.drop(columns=columns, inplace=True)
    return df


def apply_pca_test(df, columns, pca_name, n_components):
    # Load model PCA
    pca = joblib.load(f"model/pca_{pca_name}.joblib")
    princ_comp = pca.transform(df[columns])
    pc_cols = [f"pc{pca_name}_{i+1}" for i in range(n_components)]
    df[pc_cols] = pd.DataFrame(princ_comp, index=df.index, columns=pc_cols)

    # Drop kolom asli
    df.drop(columns=columns, inplace=True)
    return df

pca_numerical_columns_1 = ['Curricular_units_1st_sem_enrolled',
    'Curricular_units_1st_sem_evaluations',
    'Curricular_units_1st_sem_approved',
    'Curricular_units_1st_sem_grade',
    'Curricular_units_2nd_sem_enrolled',
    'Curricular_units_2nd_sem_evaluations',
    'Curricular_units_2nd_sem_approved',
    'Curricular_units_2nd_sem_grade',]
pca_numerical_columns_2 = [
    'Previous_qualification_grade',
    'Admission_grade',
    'Age_at_enrollment',
    'Unemployment_rate',
    'Inflation_rate',
    'GDP',]

train_pca_df = apply_pca_train(train_pca_df, pca_numerical_columns_1, 5, 1)
train_pca_df = apply_pca_train(train_pca_df, pca_numerical_columns_2, 2, 2)

test_pca_df = apply_pca_test(test_pca_df, pca_numerical_columns_1, 1, 5)
test_pca_df = apply_pca_test(test_pca_df, pca_numerical_columns_2, 2, 2)

"""### Modelling

### GridSearch
"""

param_grid = {
    "penalty": ["l1","l2"],
    "C": [0.01, 0.1, 1]
}

log_model = LogisticRegression(random_state=123)

CV_lr = GridSearchCV(estimator=log_model, param_grid=param_grid, cv=5, n_jobs=-1)
CV_lr.fit(train_pca_df, y_smote)

tree_model = DecisionTreeClassifier(random_state=123)

param_grid = {
    'max_features': ['auto', 'sqrt', 'log2'],
    'max_depth' : [5, 6, 7, 8],
    'criterion' :['gini', 'entropy']
}

CV_tree = GridSearchCV(estimator=tree_model, param_grid=param_grid, cv=5, n_jobs=-1)
CV_tree.fit(train_pca_df, y_smote)

print("best parameters: ", CV_tree.best_params_)

"""### Decision Tree"""

tree_model = DecisionTreeClassifier(
    random_state=123,
    criterion='gini',
    max_depth=8,
    max_features='sqrt'
)

tree_model.fit(train_pca_df, y_smote)
joblib.dump(tree_model, "model/tree_model.joblib")

"""### Random Forest"""

rdf_model = RandomForestClassifier(random_state=123)

param_grid = {
    'n_estimators': [200, 500],
    'max_features': ['auto', 'sqrt', 'log2'],
    'max_depth' : [6, 7, 8],
    'criterion' :['gini', 'entropy']
}

CV_rdf = GridSearchCV(estimator=rdf_model, param_grid=param_grid, cv=5, n_jobs=-1)
CV_rdf.fit(train_pca_df, y_smote)

"""### KNN"""

"""Modeling K-Nearest Neighbors (KNN)"""

# Inisialisasi model KNN
knn_model = KNeighborsClassifier(n_neighbors=5)  # Kamu bisa sesuaikan nilai k-nya

# Training model
knn_model.fit(train_pca_df, y_smote)

# Simpan model
joblib.dump(knn_model, "model/knn_model.joblib")

# Prediksi
y_pred_knn = knn_model.predict(test_pca_df)

# Evaluasi
print("Classification Report (KNN):")
print(classification_report(y_test_encoded, y_pred_knn, target_names=encoder.classes_))

print("Confusion Matrix (KNN):")
print(confusion_matrix(y_test_encoded, y_pred_knn))

print("Akurasi (KNN):", accuracy_score(y_test_encoded, y_pred_knn))

"""Logistic Regression"""

# Inisialisasi model Logistic Regression
logreg_model = LogisticRegression(
    max_iter=1000,
    solver='lbfgs',
    multi_class='multinomial',
    random_state=42
)

# Training model
logreg_model.fit(train_pca_df, y_smote)

# Simpan model
joblib.dump(logreg_model, "model/logreg_model.joblib")

# Prediksi
y_pred_logreg = logreg_model.predict(test_pca_df)

# Evaluasi
print("Classification Report (Logistic Regression):")
print(classification_report(y_test_encoded, y_pred_logreg, target_names=encoder.classes_))

print("Confusion Matrix (Logistic Regression):")
print(confusion_matrix(y_test_encoded, y_pred_logreg))

print("Akurasi (Logistic Regression):", accuracy_score(y_test_encoded, y_pred_logreg))

"""### Evaluasi"""

def evaluating(y_pred, y_true):
    '''Evaluasi model'''
    labels=['Graduate', 'Dropout', 'Enrolled']

    print(classification_report(y_pred=y_pred, y_true=y_true))

    cnf_matrix = confusion_matrix(y_pred=y_pred, y_true=y_true, labels=labels)
    confusion_matrix_df = pd.DataFrame(cnf_matrix, labels, labels)
    sns.heatmap(confusion_matrix_df, annot=True, annot_kws={'size': 14}, fmt='d', cmap='YlGnBu')
    plt.ylabel('True label', fontsize=15)
    plt.xlabel('Predicted label', fontsize=15)
    plt.show()

    return confusion_matrix_df

y_pred_test = tree_model.predict(test_pca_df)
y_pred_test = encoder.inverse_transform(y_pred_test)

evaluating(y_pred=y_pred_test, y_true=y_test)

# Prediksi menggunakan model KNN
y_pred_knn = knn_model.predict(test_pca_df)

# Invers transform hasil prediksi dari angka ke label asli (Graduate, Dropout, Enrolled)
y_pred_knn = encoder.inverse_transform(y_pred_knn)

# Evaluasi performa model KNN
evaluating(y_pred=y_pred_knn, y_true=y_test)

# Prediksi terhadap data uji
y_pred_logreg = logreg_model.predict(test_pca_df)

# Konversi hasil prediksi ke label asli
y_pred_logreg = encoder.inverse_transform(y_pred_logreg)

# Evaluasi performa model
evaluating(y_pred=y_pred_logreg, y_true=y_test)

!zip -r /content/file.zip /content/model

!pip install session-info

import session_info
session_info.show()